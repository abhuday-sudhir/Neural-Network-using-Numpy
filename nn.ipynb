{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a56df873",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "511ada6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    s = sigmoid(z)\n",
    "    return s * (1 - s)\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, sizes):\n",
    "        self.num_layers = len(sizes)\n",
    "        self.sizes = sizes\n",
    "        self.biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "        self.weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "    def feedforward(self, a):\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            a = sigmoid(np.dot(w, a) + b)\n",
    "        return a\n",
    "\n",
    "    def SGD(self, train_data, epochs, batch_size, eta, test_data=None):\n",
    "        if test_data:\n",
    "            n_test = len(test_data)\n",
    "        n = len(train_data)\n",
    "        for i in range(epochs):\n",
    "            np.random.shuffle(train_data)\n",
    "            mini_batches = [train_data[k:k+batch_size] for k in range(0, n, batch_size)]\n",
    "            for mini_batch in mini_batches:\n",
    "                self.update_mini_batch(mini_batch, eta)\n",
    "\n",
    "            if test_data:\n",
    "                print(f\"Epoch {i}: {self.evaluate(test_data)} / {n_test}\")\n",
    "            else:\n",
    "                print(f\"Epoch {i} complete\")\n",
    "\n",
    "    def update_mini_batch(self, mini_batch, eta):\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "        for x, y in mini_batch:\n",
    "            delta_nabla_b, delta_nabla_w = self.back_propagation(x, y)\n",
    "            nabla_b = [nb + dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "            nabla_w = [nw + dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "        self.weights = [w - (eta / len(mini_batch)) * nw for w, nw in zip(self.weights, nabla_w)]\n",
    "        self.biases = [b - (eta / len(mini_batch)) * nb for b, nb in zip(self.biases, nabla_b)]\n",
    "\n",
    "    def back_propagation(self, x, y):\n",
    "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
    "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
    "\n",
    "        activation = x\n",
    "        activations = [x]  # List to store all activations layer by layer\n",
    "        zs = []            # List to store all z vectors layer by layer\n",
    "\n",
    "        for w, b in zip(self.weights, self.biases):\n",
    "            z = np.dot(w, activation) + b\n",
    "            zs.append(z)\n",
    "            activation = sigmoid(z)\n",
    "            activations.append(activation)\n",
    "\n",
    "        # Backward pass\n",
    "        delta = self.cost_derivative(activations[-1], y) * sigmoid_prime(zs[-1])\n",
    "        nabla_b[-1] = delta\n",
    "        nabla_w[-1] = np.dot(delta, activations[-2].T)\n",
    "\n",
    "        for l in range(2, self.num_layers):\n",
    "            z = zs[-l]\n",
    "            sp = sigmoid_prime(z)\n",
    "            delta = np.dot(self.weights[-l+1].T, delta) * sp\n",
    "            nabla_b[-l] = delta\n",
    "            nabla_w[-l] = np.dot(delta, activations[-l-1].T)\n",
    "\n",
    "        return nabla_b, nabla_w\n",
    "\n",
    "    def evaluate(self, test_data):\n",
    "        test_results = [(np.argmax(self.feedforward(x)), np.argmax(y)) for (x, y) in test_data]\n",
    "        return sum(int(pred == actual) for (pred, actual) in test_results)\n",
    "\n",
    "    def cost_derivative(self, output_activations, y):\n",
    "        return output_activations - y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd737b3",
   "metadata": {},
   "source": [
    "# Loading MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d0ade39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist=fetch_openml('mnist_784', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "885bcbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x,y=mnist['data'],mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "88289bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "22a4c0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(y, num_classes=10):\n",
    "    y_encoded=np.zeros((len(y),num_classes))\n",
    "    for i in range(len(y)):\n",
    "        y_encoded[i][int(y[i])]=1\n",
    "    return y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d2227480",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=x.astype(np.float32) / 255.0 # Normalize the data \n",
    "x=np.round(x,3) \n",
    "y=one_hot_encode(y.to_numpy().astype(np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9aeb3959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(1.0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(x[0])\n",
    "x[0][161]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6c352564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], shape=(70000, 10))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3871e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(x[i].reshape(-1, 1), y[i].reshape(-1, 1)) for i in range(len(x))]\n",
    "train_data,test_data=data[:60000],data[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "be020c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 9080 / 10000\n",
      "Epoch 1: 9241 / 10000\n",
      "Epoch 2: 9254 / 10000\n",
      "Epoch 3: 9300 / 10000\n",
      "Epoch 4: 9350 / 10000\n",
      "Epoch 5: 9354 / 10000\n",
      "Epoch 6: 9363 / 10000\n",
      "Epoch 7: 9372 / 10000\n",
      "Epoch 8: 9435 / 10000\n",
      "Epoch 9: 9406 / 10000\n",
      "Epoch 10: 9394 / 10000\n",
      "Epoch 11: 9402 / 10000\n",
      "Epoch 12: 9451 / 10000\n",
      "Epoch 13: 9410 / 10000\n",
      "Epoch 14: 9454 / 10000\n",
      "Epoch 15: 9419 / 10000\n",
      "Epoch 16: 9418 / 10000\n",
      "Epoch 17: 9458 / 10000\n",
      "Epoch 18: 9460 / 10000\n",
      "Epoch 19: 9467 / 10000\n",
      "Epoch 20: 9418 / 10000\n",
      "Epoch 21: 9485 / 10000\n",
      "Epoch 22: 9458 / 10000\n",
      "Epoch 23: 9466 / 10000\n",
      "Epoch 24: 9479 / 10000\n",
      "Epoch 25: 9494 / 10000\n",
      "Epoch 26: 9484 / 10000\n",
      "Epoch 27: 9482 / 10000\n",
      "Epoch 28: 9498 / 10000\n",
      "Epoch 29: 9434 / 10000\n",
      "Epoch 30: 9470 / 10000\n",
      "Epoch 31: 9477 / 10000\n",
      "Epoch 32: 9490 / 10000\n",
      "Epoch 33: 9491 / 10000\n",
      "Epoch 34: 9476 / 10000\n",
      "Epoch 35: 9471 / 10000\n",
      "Epoch 36: 9490 / 10000\n",
      "Epoch 37: 9503 / 10000\n",
      "Epoch 38: 9491 / 10000\n",
      "Epoch 39: 9510 / 10000\n",
      "Epoch 40: 9520 / 10000\n",
      "Epoch 41: 9498 / 10000\n",
      "Epoch 42: 9479 / 10000\n",
      "Epoch 43: 9514 / 10000\n",
      "Epoch 44: 9485 / 10000\n",
      "Epoch 45: 9481 / 10000\n",
      "Epoch 46: 9508 / 10000\n",
      "Epoch 47: 9489 / 10000\n",
      "Epoch 48: 9496 / 10000\n",
      "Epoch 49: 9504 / 10000\n"
     ]
    }
   ],
   "source": [
    "network=Network([784,20,20,10])\n",
    "network.SGD(train_data,epochs=50,batch_size=10,eta=3,test_data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296fd120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
